{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZgjTWDbuodNx4y88Ajqd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jegovila/SI4/blob/main/Proyectos/Pr%C3%A1ctica_Clasificaci%C3%B3n_rgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from IPython import display as idp\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "wHebbVhCNQj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Webcam"
      ],
      "metadata": {
        "id": "bze5v9X94hRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def js_to_image(js_reply):\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      // await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "OEtiZsNKL_ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "kb2Jc69YOgEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generar Dataset"
      ],
      "metadata": {
        "id": "i4JPCxm64lE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sx = 200\n",
        "sy = 200\n",
        "ex = 400\n",
        "ey = 350\n",
        "colors = []\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    # loop through detections and draw them on transparent overlay image\n",
        "    bbox_array = cv2.rectangle(bbox_array,(sx,sy),(ex,ey),(255,0,0),2)\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n",
        "\n",
        "    if not js_reply:\n",
        "      while True:\n",
        "        filename = take_photo()\n",
        "        print('Saved to {}'.format(filename))\n",
        "        I = cv2.imread(\"photo.jpg\")\n",
        "        I = I[sy:ey,sx:ex]\n",
        "\n",
        "        plt.figure(figsize=(3,4))\n",
        "        plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        print(\"z para tomar otra foto\")\n",
        "        print(\"q para salir\")\n",
        "        print(\"introduce el color\")\n",
        "        color_label = input()\n",
        "\n",
        "        if color_label == \"q\":\n",
        "          break\n",
        "\n",
        "        elif color_label != \"z\":\n",
        "          height, width = I.shape[:2]\n",
        "          for i in range(50):\n",
        "            xpos = np.random.randint(width)\n",
        "            ypos = np.random.randint(height)\n",
        "            b, g, r = I[ypos, xpos]\n",
        "            colors.append([r, g, b, color_label])\n",
        "\n",
        "          idp.display(plt.gcf())\n",
        "          idp.clear_output(wait=True)\n",
        "          break\n",
        "\n",
        "        elif color_label == \"z\":\n",
        "          idp.display(plt.gcf())\n",
        "          idp.clear_output(wait=True)\n",
        "          video_stream()\n",
        "          js_reply = video_frame(label_html, bbox)\n",
        "          break\n",
        "\n",
        "      if color_label == \"q\":\n",
        "        df = pd.DataFrame(colors, columns=['R', 'G', 'B', 'Label'])\n",
        "        df.to_csv('colors.csv', index=False)\n",
        "        break"
      ],
      "metadata": {
        "id": "FAn8YQ92Ojl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento"
      ],
      "metadata": {
        "id": "NmKk0_Se4vxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pickle"
      ],
      "metadata": {
        "id": "9i3H7u374xs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('colors.csv')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "RogHKufd41Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el siguiente bloque en blanco es neceario obtener los datos de entrada x/y y separarlos en x_train/test y y_train/test."
      ],
      "metadata": {
        "id": "hBWNiipgup1t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rKDe6b0duyx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegir el modelo. Completar las siguientes líneas."
      ],
      "metadata": {
        "id": "7TCt6lkgwlrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =                                           # <------ completar aqui\n",
        "model.fit(x_train, y_train.ravel())\n",
        "\n",
        "print('Train score',)                             # <------ completar aqui\n",
        "print('Test score',)                              # <------ completar aqui\n",
        "\n",
        "yp = model.predict(x)\n",
        "\n",
        "print('Metricas: \\n', metrics.classification_report(y,yp))\n",
        "print('Confusion matrix: \\n', metrics.confusion_matrix(y,yp))\n",
        "\n",
        "pickle.dump(model,open('model.sav','wb'))"
      ],
      "metadata": {
        "id": "gpbIqFim424d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicción"
      ],
      "metadata": {
        "id": "vo-ksYwH4677"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open('model.sav', 'rb'))"
      ],
      "metadata": {
        "id": "Nzrxo9-h5Gvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sx = 200\n",
        "sy = 200\n",
        "ex = 400\n",
        "ey = 350\n",
        "colors = []\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    # loop through detections and draw them on transparent overlay image\n",
        "    bbox_array = cv2.rectangle(bbox_array,(sx,sy),(ex,ey),(255,0,0),2)\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n",
        "\n",
        "    if not js_reply:\n",
        "      filename = take_photo()\n",
        "      print('Saved to {}'.format(filename))\n",
        "      I = cv2.imread(\"photo.jpg\")\n",
        "      I = I[sy:ey,sx:ex]\n",
        "\n",
        "      plt.figure(figsize=(3,4))\n",
        "      plt.imshow(cv2.cvtColor(I, cv2.COLOR_BGR2RGB))\n",
        "      plt.axis(\"off\")\n",
        "      plt.show()\n",
        "\n",
        "      data = []\n",
        "      for i in range(3):\n",
        "        channel = I[:, :, 2-i]\n",
        "        indices = np.where(channel != 0)[0]\n",
        "        media = np.mean(channel[indices])\n",
        "        data.append(int(media))\n",
        "      print(data)\n",
        "      break"
      ],
      "metadata": {
        "id": "2Hulf0AY48Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([data])"
      ],
      "metadata": {
        "id": "vuXiwB2k5ILN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
